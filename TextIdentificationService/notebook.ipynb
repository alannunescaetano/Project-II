{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR WITH KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imutils\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import build_montages\n",
    "from PIL import Image\n",
    "\n",
    "from models import ResNet\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-1\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "A-Z\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load A-Z dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_a_z_font_dataset(rootdir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(rootdir):\n",
    "        for filename in filenames:\n",
    "            labels.append(int(filename[8:11])-11)\n",
    "            \n",
    "            image = cv2.imread(os.path.join(dirpath, filename))\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            (thresh, bwImage) = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "            width, height = bwImage.shape\n",
    "            totalpixels = width * height\n",
    "            if cv2.countNonZero(bwImage) < totalpixels / 2:\n",
    "                bwImage = np.invert(bwImage)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            if tW > tH:\n",
    "                bwImage = imutils.resize(bwImage, width=128)\n",
    "            else:\n",
    "                bwImage = imutils.resize(bwImage, height=128)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            dX = int(max(0, 128 - tW) / 2.0)\n",
    "            dY = int(max(0, 128 - tH) / 2.0)\n",
    "\n",
    "            padded = cv2.copyMakeBorder(bwImage, top=dY, bottom=dY,\n",
    "                left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "                value=(255, 255, 255))\n",
    "                \n",
    "            padded = cv2.resize(padded, (128, 128))\n",
    "            padded = padded.astype(\"float32\") / 255.0\n",
    "            padded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "            image = padded.reshape((128, 128))\n",
    "            data.append(image)                    \n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, labels) = load_a_z_font_dataset(r'C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\datasets\\a_z_font')\n",
    "\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0\n",
    "\n",
    "le = LabelBinarizer()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "ounts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training assesment balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  labels, test_size=0.20, stratify=None, random_state=42) #VER COMO USAR O STRATIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=10, zoom_range=0.05, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15, horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "                     (64, 64, 128, 256), reg=0.0005)\n",
    "                     \n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 544s 1s/step - loss: 4.1624 - accuracy: 0.2920 - val_loss: 2.0881 - val_accuracy: 0.5404\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 562s 1s/step - loss: 2.2030 - accuracy: 0.6396 - val_loss: 1.4067 - val_accuracy: 0.6800\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 531s 1s/step - loss: 1.5606 - accuracy: 0.7365 - val_loss: 1.1445 - val_accuracy: 0.7368\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 8775s 23s/step - loss: 1.3165 - accuracy: 0.7717 - val_loss: 1.0058 - val_accuracy: 0.7778\n",
      "Epoch 5/50\n",
      "135/375 [=========>....................] - ETA: 7:13:42 - loss: 1.2227 - accuracy: 0.7852"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS), \n",
    "            validation_data=(testX, testY), \n",
    "            #steps_per_epoch=len(trainX),\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=classWeight,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.78      0.84      0.81       323\n",
      "           B       0.87      0.85      0.86       211\n",
      "           C       0.71      0.58      0.64       257\n",
      "           D       0.86      0.86      0.86       235\n",
      "           E       0.85      0.90      0.87       288\n",
      "           F       0.92      0.89      0.91       236\n",
      "           G       0.76      0.87      0.81       217\n",
      "           H       0.80      0.87      0.83       254\n",
      "           I       0.73      0.32      0.45       253\n",
      "           J       0.86      0.82      0.84       216\n",
      "           K       0.90      0.91      0.91       216\n",
      "           L       0.88      0.87      0.88       242\n",
      "           M       0.82      0.86      0.84       226\n",
      "           N       0.86      0.85      0.86       274\n",
      "           O       0.68      0.31      0.43       279\n",
      "           P       0.81      0.86      0.84       212\n",
      "           Q       0.74      0.86      0.80       206\n",
      "           R       0.85      0.83      0.84       273\n",
      "           S       0.65      0.49      0.56       257\n",
      "           T       0.91      0.89      0.90       267\n",
      "           U       0.85      0.83      0.84       228\n",
      "           V       0.69      0.42      0.52       217\n",
      "           W       0.57      0.48      0.52       206\n",
      "           X       0.59      0.68      0.63       186\n",
      "           Y       0.86      0.86      0.86       240\n",
      "           Z       0.65      0.56      0.60       210\n",
      "           a       0.81      0.86      0.83       242\n",
      "           b       0.89      0.88      0.89       215\n",
      "           c       0.64      0.66      0.65       220\n",
      "           d       0.95      0.90      0.93       221\n",
      "           e       0.80      0.83      0.82       227\n",
      "           f       0.75      0.89      0.81       215\n",
      "           g       0.71      0.85      0.77       216\n",
      "           h       0.95      0.83      0.89       244\n",
      "           i       0.86      0.87      0.87       248\n",
      "           j       0.92      0.84      0.88       192\n",
      "           k       0.88      0.92      0.90       198\n",
      "           l       0.51      0.75      0.61       217\n",
      "           m       0.85      0.89      0.87       199\n",
      "           n       0.85      0.79      0.82       226\n",
      "           o       0.50      0.66      0.57       218\n",
      "           p       0.86      0.78      0.81       228\n",
      "           q       0.77      0.84      0.80       215\n",
      "           r       0.87      0.89      0.88       238\n",
      "           s       0.57      0.65      0.61       222\n",
      "           t       0.77      0.84      0.80       230\n",
      "           u       0.85      0.85      0.85       215\n",
      "           v       0.59      0.70      0.64       214\n",
      "           w       0.56      0.69      0.62       227\n",
      "           x       0.67      0.62      0.64       218\n",
      "           y       0.75      0.82      0.78       235\n",
      "           z       0.64      0.67      0.65       220\n",
      "\n",
      "    accuracy                           0.77     11989\n",
      "   macro avg       0.77      0.77      0.77     11989\n",
      "weighted avg       0.78      0.77      0.77     11989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "images = [] \n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "\n",
    "cv2.imshow(\"OCR Results\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading OCR model...\n",
      "C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_only_capital.model\n",
      "[(array([[[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.50980395],\n",
      "        ...,\n",
      "        [0.50980395],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.09411765],\n",
      "        ...,\n",
      "        [0.07843138],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.7764706 ],\n",
      "        ...,\n",
      "        [0.5568628 ],\n",
      "        [1.        ],\n",
      "        [1.        ]]], dtype=float32), (44, 74, 54, 62)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (104, 74, 39, 62)), (array([[[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        ...,\n",
      "        [1.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.7137255 ],\n",
      "        ...,\n",
      "        [0.21176471],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.50980395],\n",
      "        ...,\n",
      "        [0.        ],\n",
      "        [1.        ],\n",
      "        [1.        ]],\n",
      "\n",
      "       [[1.        ],\n",
      "        [1.        ],\n",
      "        [0.7607843 ],\n",
      "        ...,\n",
      "        [0.5176471 ],\n",
      "        [1.        ],\n",
      "        [1.        ]]], dtype=float32), (142, 74, 55, 62)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (201, 73, 45, 63)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (251, 74, 44, 61)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (301, 74, 43, 62)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (376, 73, 45, 64)), (array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]], dtype=float32), (430, 74, 41, 62))]\n",
      "prob: 0.995669\n",
      "[INFO] A - 99.57%\n",
      "prob: 0.99220395\n",
      "[INFO] F - 99.22%\n",
      "prob: 0.9970553\n",
      "[INFO] A - 99.71%\n",
      "prob: 0.9912935\n",
      "[INFO] S - 99.13%\n",
      "prob: 0.9154705\n",
      "[INFO] T - 91.55%\n",
      "prob: 0.9981325\n",
      "[INFO] E - 99.81%\n",
      "prob: 0.98979795\n",
      "[INFO] S - 98.98%\n",
      "prob: 0.99701226\n",
      "[INFO] E - 99.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "\n",
    "print(\"[INFO] loading OCR model...\")\n",
    "model = load_model(model_path)\n",
    "print(model_path)\n",
    "\n",
    "image_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\images\\placa-perigo.png\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "\n",
    "chars = []\n",
    "\n",
    "for c in cnts:\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\tif (w >= 20 and w <= 150) and (h >= 15 and h <= 120):\n",
    "\t\troi = gray[y:y + h, x:x + w]\n",
    "\t\tthresh = cv2.threshold(roi, 0, 255,\n",
    "\t\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\t\t(tH, tW) = thresh.shape\n",
    "\n",
    "\t\tif tW > tH:\n",
    "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
    "\t\telse:\n",
    "\t\t\tthresh = imutils.resize(thresh, height=32)\n",
    "\n",
    "\t\t(tH, tW) = thresh.shape\n",
    "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
    "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "\t\tpadded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
    "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=(255, 255, 255))\n",
    "\t\t\n",
    "\t\tpadded = cv2.resize(padded, (32, 32))\n",
    "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
    "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "\t\tchars.append((padded, (x, y, w, h)))\n",
    "\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "\n",
    "preds = model.predict(chars)\n",
    "\n",
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "\ti = np.argmax(pred)\n",
    "\tprob = pred[i]\n",
    "\tif prob > 0.8:\n",
    "\t\tprint(\"prob:\",prob)\n",
    "\t\tlabel = labelNames[i]\n",
    "\n",
    "\t\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\tcv2.putText(image, label, (x - 10, y - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83d1aa5d07da1bd447310e58fa53538eb934dc03a03373045c879c3b2a330cde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
