{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR WITH KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imutils\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import build_montages\n",
    "from PIL import Image\n",
    "\n",
    "from models import ResNet\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "EPOCHS = 5\n",
    "INIT_LR = 1e-1\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "A-Z\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load A-Z dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_a_z_font_dataset(rootdir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(rootdir):\n",
    "        for filename in filenames:\n",
    "            \n",
    "            labels.append(int(filename[8:11])-1)\n",
    "            #print(int(filename[8:11])-11)\n",
    "            \n",
    "            image = cv2.imread(os.path.join(dirpath, filename))\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            (thresh, bwImage) = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "            width, height = bwImage.shape\n",
    "            totalpixels = width * height\n",
    "            if cv2.countNonZero(bwImage) < totalpixels / 2:\n",
    "                bwImage = np.invert(bwImage)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            if tW > tH:\n",
    "                bwImage = imutils.resize(bwImage, width=32)\n",
    "            else:\n",
    "                bwImage = imutils.resize(bwImage, height=32)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            dX = int(max(0, 32 - tW) / 2.0)\n",
    "            dY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "            padded = cv2.copyMakeBorder(bwImage, top=dY, bottom=dY,\n",
    "                left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "                value=(255, 255, 255))\n",
    "\n",
    "            data.append(padded)                    \n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, labels) = load_a_z_font_dataset(r'C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\datasets\\a_z_test')\n",
    "\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0\n",
    "\n",
    "le = LabelBinarizer()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "ounts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training assesment balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=10, zoom_range=0.05, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15, horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "                     (64, 64, 128, 256), reg=0.0005)\n",
    "                     \n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 47s 2s/step - loss: 1.1400 - accuracy: 0.6938 - val_loss: 1.5231 - val_accuracy: 0.3997\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.6802 - accuracy: 0.8853 - val_loss: 0.5075 - val_accuracy: 0.9112\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.5017 - accuracy: 0.9165 - val_loss: 0.4597 - val_accuracy: 0.9302\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 48s 2s/step - loss: 0.4268 - accuracy: 0.9333 - val_loss: 0.4178 - val_accuracy: 0.9239\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 49s 2s/step - loss: 0.3794 - accuracy: 0.9479 - val_loss: 0.5037 - val_accuracy: 0.8985\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS), \n",
    "            validation_data=(testX, testY), \n",
    "            #steps_per_epoch=len(trainX),\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=classWeight,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.87      0.92       315\n",
      "           C       0.77      0.98      0.87       226\n",
      "           B       0.97      0.85      0.91       247\n",
      "\n",
      "    accuracy                           0.90       788\n",
      "   macro avg       0.90      0.90      0.90       788\n",
      "weighted avg       0.91      0.90      0.90       788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = \"ABC\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full_test_ABCD.model\"\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full_test_ABCD.model\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "#labelNames = \"ACBDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = \"ABC\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "images = [] \n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    #print(prediction)\n",
    "\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "\n",
    "cv2.imshow(\"OCR Results\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading OCR model...\n",
      "C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full_test_ABCD.model\n",
      "prob: 0.97940356\n",
      "[INFO] A - 97.94%\n",
      "prob: 0.9796922\n",
      "[INFO] A - 97.97%\n",
      "prob: 0.97940356\n",
      "[INFO] A - 97.94%\n",
      "prob: 0.98329204\n",
      "[INFO] A - 98.33%\n",
      "prob: 0.9798395\n",
      "[INFO] A - 97.98%\n",
      "prob: 0.98440015\n",
      "[INFO] A - 98.44%\n",
      "prob: 0.98329204\n",
      "[INFO] A - 98.33%\n",
      "prob: 0.9835882\n",
      "[INFO] A - 98.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full_test_ABCD.model\"\n",
    "\n",
    "print(\"[INFO] loading OCR model...\")\n",
    "model = load_model(model_path)\n",
    "print(model_path)\n",
    "\n",
    "image_path = r\"images\\afastese.PNG\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "\n",
    "chars = []\n",
    "            \n",
    "\n",
    "for c in cnts:\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\tif (w >= 20 and w <= 150) and (h >= 15 and h <= 120):\n",
    "\t\troi = gray[y:y + h, x:x + w]\n",
    "\t\t(t, bwImage) = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "\t\t(tW, tH) = bwImage.shape\n",
    "\t\ttotalpixels = tW * tH\n",
    "\t\t\n",
    "\t\tif cv2.countNonZero(bwImage) < totalpixels / 2:\n",
    "\t\t\tbwImage = np.invert(bwImage)\n",
    "\n",
    "\t\tif tW > tH:\n",
    "\t\t\tbwImage = imutils.resize(bwImage, width=32)\n",
    "\t\telse:\n",
    "\t\t\tbwImage = imutils.resize(bwImage, height=32)\n",
    "\n",
    "\t\t(tH, tW) = bwImage.shape\n",
    "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
    "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "\t\tpadded = cv2.copyMakeBorder(t, top=dY, bottom=dY,\n",
    "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=(255, 255, 255))\n",
    "\t\t\n",
    "\t\tpadded = cv2.resize(padded, (32, 32))\n",
    "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
    "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "\t\tcv2.imshow(\"Image\", padded)\n",
    "\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\tchars.append((padded, (x, y, w, h)))\n",
    "\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "\n",
    "\n",
    "preds = model.predict(chars)\n",
    "\n",
    "#labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = \"ABC\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "\ti = np.argmax(pred)\n",
    "\tprob = pred[i]\n",
    "\tif prob > 0.8:\n",
    "\t\tprint(\"prob:\",prob)\n",
    "\t\tlabel = labelNames[i]\n",
    "\n",
    "\t\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\tcv2.putText(image, label, (x - 10, y - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83d1aa5d07da1bd447310e58fa53538eb934dc03a03373045c879c3b2a330cde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
