{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR WITH KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imutils\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import build_montages\n",
    "from PIL import Image\n",
    "\n",
    "from models import ResNet\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-1\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "A-Z\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load A-Z dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_a_z_font_dataset(rootdir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(rootdir):\n",
    "        for filename in filenames:\n",
    "            \n",
    "            labels.append(int(filename[8:11])-1)\n",
    "            #print(int(filename[8:11])-11)\n",
    "            \n",
    "            image = cv2.imread(os.path.join(dirpath, filename))\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            (thresh, bwImage) = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "            width, height = bwImage.shape\n",
    "            totalpixels = width * height\n",
    "            if cv2.countNonZero(bwImage) < totalpixels / 2:\n",
    "                bwImage = np.invert(bwImage)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            if tW > tH:\n",
    "                bwImage = imutils.resize(bwImage, width=32)\n",
    "            else:\n",
    "                bwImage = imutils.resize(bwImage, height=32)\n",
    "\n",
    "            (tH, tW) = bwImage.shape\n",
    "            dX = int(max(0, 32 - tW) / 2.0)\n",
    "            dY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "            padded = cv2.copyMakeBorder(bwImage, top=dY, bottom=dY,\n",
    "                left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "                value=(255, 255, 255))\n",
    "\n",
    "            data.append(padded)                    \n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, labels) = load_a_z_font_dataset(r'C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\datasets\\a_z_font')\n",
    "\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0\n",
    "\n",
    "le = LabelBinarizer()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "ounts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training assesment balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=10, zoom_range=0.05, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15, horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "                     (64, 64, 128, 256), reg=0.0005)\n",
    "                     \n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 745s 2s/step - loss: 3.9536 - accuracy: 0.3173 - val_loss: 1.9762 - val_accuracy: 0.5670\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 760s 2s/step - loss: 2.0484 - accuracy: 0.6646 - val_loss: 1.4575 - val_accuracy: 0.6530\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 752s 2s/step - loss: 1.5032 - accuracy: 0.7489 - val_loss: 1.0219 - val_accuracy: 0.7720\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 751s 2s/step - loss: 1.2889 - accuracy: 0.7778 - val_loss: 0.9374 - val_accuracy: 0.7853\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 754s 2s/step - loss: 1.1894 - accuracy: 0.7950 - val_loss: 0.8792 - val_accuracy: 0.8065\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 752s 2s/step - loss: 1.1297 - accuracy: 0.8034 - val_loss: 0.8699 - val_accuracy: 0.7993\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 754s 2s/step - loss: 1.0834 - accuracy: 0.8097 - val_loss: 0.8210 - val_accuracy: 0.8137\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 750s 2s/step - loss: 1.0484 - accuracy: 0.8166 - val_loss: 0.8027 - val_accuracy: 0.8204\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 749s 2s/step - loss: 1.0224 - accuracy: 0.8206 - val_loss: 0.7924 - val_accuracy: 0.8250\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 751s 2s/step - loss: 0.9980 - accuracy: 0.8240 - val_loss: 0.7797 - val_accuracy: 0.8243\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.9853 - accuracy: 0.8253 - val_loss: 0.7742 - val_accuracy: 0.8258\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 784s 2s/step - loss: 0.9680 - accuracy: 0.8276 - val_loss: 0.7550 - val_accuracy: 0.8354\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 861s 2s/step - loss: 0.9532 - accuracy: 0.8316 - val_loss: 0.7528 - val_accuracy: 0.8319\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 722s 2s/step - loss: 0.9421 - accuracy: 0.8345 - val_loss: 0.7460 - val_accuracy: 0.8311\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 797s 2s/step - loss: 0.9289 - accuracy: 0.8350 - val_loss: 0.7378 - val_accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 858s 2s/step - loss: 0.9191 - accuracy: 0.8372 - val_loss: 0.7303 - val_accuracy: 0.8343\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 784s 2s/step - loss: 0.9101 - accuracy: 0.8371 - val_loss: 0.7257 - val_accuracy: 0.8385\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 841s 2s/step - loss: 0.9013 - accuracy: 0.8409 - val_loss: 0.7238 - val_accuracy: 0.8390\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 835s 2s/step - loss: 0.8953 - accuracy: 0.8412 - val_loss: 0.7183 - val_accuracy: 0.8381\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 766s 2s/step - loss: 0.8864 - accuracy: 0.8425 - val_loss: 0.7119 - val_accuracy: 0.8414\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 872s 2s/step - loss: 0.8743 - accuracy: 0.8450 - val_loss: 0.7060 - val_accuracy: 0.8417\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 855s 2s/step - loss: 0.8728 - accuracy: 0.8459 - val_loss: 0.7102 - val_accuracy: 0.8421\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 858s 2s/step - loss: 0.8684 - accuracy: 0.8470 - val_loss: 0.7066 - val_accuracy: 0.8411\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 813s 2s/step - loss: 0.8612 - accuracy: 0.8465 - val_loss: 0.7001 - val_accuracy: 0.8419\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 751s 2s/step - loss: 0.8545 - accuracy: 0.8473 - val_loss: 0.6959 - val_accuracy: 0.8472\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.8557 - accuracy: 0.8477 - val_loss: 0.6934 - val_accuracy: 0.8444\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 746s 2s/step - loss: 0.8472 - accuracy: 0.8481 - val_loss: 0.6921 - val_accuracy: 0.8461\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.8400 - accuracy: 0.8517 - val_loss: 0.6878 - val_accuracy: 0.8472\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 743s 2s/step - loss: 0.8385 - accuracy: 0.8518 - val_loss: 0.6895 - val_accuracy: 0.8463\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 748s 2s/step - loss: 0.8354 - accuracy: 0.8518 - val_loss: 0.6863 - val_accuracy: 0.8469\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 744s 2s/step - loss: 0.8306 - accuracy: 0.8524 - val_loss: 0.6826 - val_accuracy: 0.8488\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 746s 2s/step - loss: 0.8284 - accuracy: 0.8541 - val_loss: 0.6806 - val_accuracy: 0.8480\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.8225 - accuracy: 0.8541 - val_loss: 0.6807 - val_accuracy: 0.8487\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 743s 2s/step - loss: 0.8187 - accuracy: 0.8547 - val_loss: 0.6785 - val_accuracy: 0.8484\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 747s 2s/step - loss: 0.8175 - accuracy: 0.8563 - val_loss: 0.6745 - val_accuracy: 0.8498\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 742s 2s/step - loss: 0.8150 - accuracy: 0.8559 - val_loss: 0.6716 - val_accuracy: 0.8512\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 744s 2s/step - loss: 0.8078 - accuracy: 0.8575 - val_loss: 0.6729 - val_accuracy: 0.8520\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 746s 2s/step - loss: 0.8093 - accuracy: 0.8561 - val_loss: 0.6727 - val_accuracy: 0.8484\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 743s 2s/step - loss: 0.8067 - accuracy: 0.8557 - val_loss: 0.6680 - val_accuracy: 0.8501\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.8018 - accuracy: 0.8592 - val_loss: 0.6674 - val_accuracy: 0.8501\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 750s 2s/step - loss: 0.7982 - accuracy: 0.8596 - val_loss: 0.6691 - val_accuracy: 0.8505\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 752s 2s/step - loss: 0.7965 - accuracy: 0.8594 - val_loss: 0.6651 - val_accuracy: 0.8535\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 779s 2s/step - loss: 0.7966 - accuracy: 0.8594 - val_loss: 0.6661 - val_accuracy: 0.8524\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 744s 2s/step - loss: 0.7912 - accuracy: 0.8593 - val_loss: 0.6628 - val_accuracy: 0.8543\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 746s 2s/step - loss: 0.7953 - accuracy: 0.8591 - val_loss: 0.6604 - val_accuracy: 0.8530\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.7866 - accuracy: 0.8605 - val_loss: 0.6599 - val_accuracy: 0.8539\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 744s 2s/step - loss: 0.7914 - accuracy: 0.8584 - val_loss: 0.6575 - val_accuracy: 0.8556\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 749s 2s/step - loss: 0.7873 - accuracy: 0.8598 - val_loss: 0.6586 - val_accuracy: 0.8540\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 745s 2s/step - loss: 0.7820 - accuracy: 0.8601 - val_loss: 0.6593 - val_accuracy: 0.8536\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 746s 2s/step - loss: 0.7797 - accuracy: 0.8624 - val_loss: 0.6571 - val_accuracy: 0.8514\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS), \n",
    "            validation_data=(testX, testY), \n",
    "            #steps_per_epoch=len(trainX),\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=classWeight,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.93      0.97      0.95       315\n",
      "           B       0.91      0.97      0.94       226\n",
      "           C       0.77      0.52      0.62       246\n",
      "           D       0.96      0.97      0.96       241\n",
      "           E       0.93      0.95      0.94       292\n",
      "           F       0.95      0.95      0.95       219\n",
      "           G       0.96      0.95      0.95       232\n",
      "           H       0.93      0.95      0.94       242\n",
      "           I       0.86      0.67      0.75       264\n",
      "           J       0.92      0.94      0.93       219\n",
      "           K       0.90      0.96      0.93       222\n",
      "           L       0.94      0.95      0.95       246\n",
      "           M       0.92      0.95      0.93       233\n",
      "           N       0.93      0.93      0.93       276\n",
      "           O       0.73      0.46      0.57       280\n",
      "           P       0.92      0.92      0.92       235\n",
      "           Q       0.92      0.96      0.94       210\n",
      "           R       0.93      0.95      0.94       281\n",
      "           S       0.67      0.51      0.58       272\n",
      "           T       0.92      0.96      0.94       266\n",
      "           U       0.87      0.86      0.87       222\n",
      "           V       0.62      0.73      0.67       220\n",
      "           W       0.64      0.74      0.69       217\n",
      "           X       0.70      0.61      0.65       219\n",
      "           Y       0.91      0.91      0.91       217\n",
      "           Z       0.66      0.64      0.65       214\n",
      "           a       0.95      0.95      0.95       235\n",
      "           b       0.97      0.90      0.93       211\n",
      "           c       0.60      0.83      0.70       216\n",
      "           d       1.00      0.94      0.97       212\n",
      "           e       0.94      0.92      0.93       249\n",
      "           f       0.92      0.93      0.93       210\n",
      "           g       0.94      0.96      0.95       210\n",
      "           h       0.98      0.93      0.95       213\n",
      "           i       0.97      0.92      0.94       229\n",
      "           j       0.98      0.94      0.96       210\n",
      "           k       0.97      0.93      0.95       210\n",
      "           l       0.67      0.88      0.76       215\n",
      "           m       0.96      0.98      0.97       212\n",
      "           n       0.91      0.93      0.92       230\n",
      "           o       0.56      0.77      0.65       233\n",
      "           p       0.90      0.92      0.91       210\n",
      "           q       0.95      0.93      0.94       214\n",
      "           r       0.96      0.91      0.93       228\n",
      "           s       0.54      0.69      0.61       228\n",
      "           t       0.97      0.94      0.95       225\n",
      "           u       0.89      0.88      0.89       211\n",
      "           v       0.66      0.51      0.58       210\n",
      "           w       0.69      0.59      0.64       210\n",
      "           x       0.67      0.78      0.72       210\n",
      "           y       0.93      0.93      0.93       212\n",
      "           z       0.65      0.65      0.65       210\n",
      "\n",
      "    accuracy                           0.85     11989\n",
      "   macro avg       0.85      0.85      0.85     11989\n",
      "weighted avg       0.86      0.85      0.85     11989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "labelNames = \"ACBDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "images = [] \n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    #print(prediction)\n",
    "\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "\n",
    "cv2.imshow(\"OCR Results\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading OCR model...\n",
      "C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_full.model\"\n",
    "\n",
    "print(\"[INFO] loading OCR model...\")\n",
    "model = load_model(model_path)\n",
    "print(model_path)\n",
    "\n",
    "image_path = r\"images\\afastese.PNG\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "\n",
    "chars = []\n",
    "            \n",
    "\n",
    "for c in cnts:\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\tif (w >= 20 and w <= 150) and (h >= 15 and h <= 120):\n",
    "\t\troi = gray[y:y + h, x:x + w]\n",
    "\t\t(t, bwImage) = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "\t\t(tW, tH) = bwImage.shape\n",
    "\t\ttotalpixels = tW * tH\n",
    "\t\t\n",
    "\t\tif cv2.countNonZero(bwImage) < totalpixels / 2:\n",
    "\t\t\tbwImage = np.invert(bwImage)\n",
    "\n",
    "\t\tif tW > tH:\n",
    "\t\t\tbwImage = imutils.resize(bwImage, width=32)\n",
    "\t\telse:\n",
    "\t\t\tbwImage = imutils.resize(bwImage, height=32)\n",
    "\n",
    "\t\t(tH, tW) = bwImage.shape\n",
    "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
    "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "\t\tpadded = cv2.copyMakeBorder(t, top=dY, bottom=dY,\n",
    "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=(255, 255, 255))\n",
    "\t\t\n",
    "\t\tpadded = cv2.resize(padded, (32, 32))\n",
    "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
    "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "\t\tcv2.imshow(\"Image\", padded)\n",
    "\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\tchars.append((padded, (x, y, w, h)))\n",
    "\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "\n",
    "\n",
    "preds = model.predict(chars)\n",
    "\n",
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "\ti = np.argmax(pred)\n",
    "\tprob = pred[i]\n",
    "\tif prob > 0.8:\n",
    "\t\tprint(\"prob:\",prob)\n",
    "\t\tlabel = labelNames[i]\n",
    "\n",
    "\t\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\tcv2.putText(image, label, (x - 10, y - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83d1aa5d07da1bd447310e58fa53538eb934dc03a03373045c879c3b2a330cde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
