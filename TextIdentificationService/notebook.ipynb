{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR WITH KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import build_montages\n",
    "from PIL import Image\n",
    "\n",
    "from models import ResNet\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-1\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "\n",
    "A-Z\n",
    "http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load A-Z dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_a_z_font_dataset(rootdir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(rootdir):\n",
    "        for filename in filenames:\n",
    "            labels.append(int(filename[3:6])-1)\n",
    "            \n",
    "            imageFile = Image.open(os.path.join(dirpath, filename))\n",
    "            image = np.array(imageFile.getdata(), dtype='uint8')\n",
    "            image = image.reshape((128, 128))\n",
    "            data.append(image)                    \n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, labels) = load_a_z_font_dataset(r'C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\datasets\\a_z_font_maiusculas')\n",
    "\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0\n",
    "\n",
    "le = LabelBinarizer()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "ounts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training assesment balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  labels, test_size=0.20, stratify=None, random_state=42) #VER COMO USAR O STRATIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alanc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=10, zoom_range=0.05, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15, horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
    "                     (64, 64, 128, 256), reg=0.0005)\n",
    "                     \n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 2.7988 - accuracy: 0.3278 - val_loss: 1.9773 - val_accuracy: 0.6734\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 233s 1s/step - loss: 1.5497 - accuracy: 0.7266 - val_loss: 1.0967 - val_accuracy: 0.8090\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.9752 - accuracy: 0.8486 - val_loss: 0.8216 - val_accuracy: 0.8550\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 238s 1s/step - loss: 0.7328 - accuracy: 0.8981 - val_loss: 0.6619 - val_accuracy: 0.9129\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 237s 1s/step - loss: 0.6212 - accuracy: 0.9165 - val_loss: 0.5469 - val_accuracy: 0.9285\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.5617 - accuracy: 0.9274 - val_loss: 0.5213 - val_accuracy: 0.9317\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.5223 - accuracy: 0.9338 - val_loss: 0.5228 - val_accuracy: 0.9269\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 253s 2s/step - loss: 0.4983 - accuracy: 0.9385 - val_loss: 0.4780 - val_accuracy: 0.9404\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 287s 2s/step - loss: 0.4721 - accuracy: 0.9443 - val_loss: 0.4679 - val_accuracy: 0.9394\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 217s 1s/step - loss: 0.4589 - accuracy: 0.9464 - val_loss: 0.4529 - val_accuracy: 0.9474\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 230s 1s/step - loss: 0.4451 - accuracy: 0.9485 - val_loss: 0.4392 - val_accuracy: 0.9449\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 242s 1s/step - loss: 0.4387 - accuracy: 0.9490 - val_loss: 0.4253 - val_accuracy: 0.9485\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 241s 1s/step - loss: 0.4256 - accuracy: 0.9537 - val_loss: 0.4225 - val_accuracy: 0.9516\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 256s 2s/step - loss: 0.4189 - accuracy: 0.9534 - val_loss: 0.4194 - val_accuracy: 0.9493\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 255s 2s/step - loss: 0.4146 - accuracy: 0.9544 - val_loss: 0.4137 - val_accuracy: 0.9531\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 255s 2s/step - loss: 0.4046 - accuracy: 0.9574 - val_loss: 0.4083 - val_accuracy: 0.9531\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 248s 1s/step - loss: 0.3988 - accuracy: 0.9578 - val_loss: 0.4007 - val_accuracy: 0.9544\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 255s 2s/step - loss: 0.3941 - accuracy: 0.9581 - val_loss: 0.3951 - val_accuracy: 0.9570\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 251s 2s/step - loss: 0.3923 - accuracy: 0.9598 - val_loss: 0.3922 - val_accuracy: 0.9574\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 247s 1s/step - loss: 0.3891 - accuracy: 0.9603 - val_loss: 0.3960 - val_accuracy: 0.9561\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 246s 1s/step - loss: 0.3813 - accuracy: 0.9604 - val_loss: 0.3870 - val_accuracy: 0.9572\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 249s 2s/step - loss: 0.3778 - accuracy: 0.9632 - val_loss: 0.3845 - val_accuracy: 0.9567\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 234s 1s/step - loss: 0.3771 - accuracy: 0.9629 - val_loss: 0.3791 - val_accuracy: 0.9599\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 232s 1s/step - loss: 0.3723 - accuracy: 0.9638 - val_loss: 0.3757 - val_accuracy: 0.9627\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 237s 1s/step - loss: 0.3719 - accuracy: 0.9641 - val_loss: 0.3781 - val_accuracy: 0.9595\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 230s 1s/step - loss: 0.3675 - accuracy: 0.9651 - val_loss: 0.3778 - val_accuracy: 0.9614\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 237s 1s/step - loss: 0.3634 - accuracy: 0.9662 - val_loss: 0.3780 - val_accuracy: 0.9604\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 247s 1s/step - loss: 0.3627 - accuracy: 0.9653 - val_loss: 0.3660 - val_accuracy: 0.9610\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 233s 1s/step - loss: 0.3575 - accuracy: 0.9681 - val_loss: 0.3639 - val_accuracy: 0.9631\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 234s 1s/step - loss: 0.3565 - accuracy: 0.9677 - val_loss: 0.3631 - val_accuracy: 0.9640\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3528 - accuracy: 0.9688 - val_loss: 0.3643 - val_accuracy: 0.9635\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 248s 1s/step - loss: 0.3510 - accuracy: 0.9691 - val_loss: 0.3627 - val_accuracy: 0.9631\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.3497 - accuracy: 0.9680 - val_loss: 0.3642 - val_accuracy: 0.9631\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.3487 - accuracy: 0.9691 - val_loss: 0.3619 - val_accuracy: 0.9631\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 238s 1s/step - loss: 0.3472 - accuracy: 0.9691 - val_loss: 0.3592 - val_accuracy: 0.9650\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 242s 1s/step - loss: 0.3464 - accuracy: 0.9700 - val_loss: 0.3521 - val_accuracy: 0.9656\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.3441 - accuracy: 0.9700 - val_loss: 0.3554 - val_accuracy: 0.9644\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3387 - accuracy: 0.9719 - val_loss: 0.3560 - val_accuracy: 0.9661\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 234s 1s/step - loss: 0.3386 - accuracy: 0.9713 - val_loss: 0.3549 - val_accuracy: 0.9644\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3385 - accuracy: 0.9715 - val_loss: 0.3511 - val_accuracy: 0.9663\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3376 - accuracy: 0.9724 - val_loss: 0.3465 - val_accuracy: 0.9665\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 234s 1s/step - loss: 0.3325 - accuracy: 0.9724 - val_loss: 0.3466 - val_accuracy: 0.9684\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3359 - accuracy: 0.9710 - val_loss: 0.3493 - val_accuracy: 0.9663\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 237s 1s/step - loss: 0.3344 - accuracy: 0.9732 - val_loss: 0.3479 - val_accuracy: 0.9659\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.3292 - accuracy: 0.9737 - val_loss: 0.3471 - val_accuracy: 0.9676\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 236s 1s/step - loss: 0.3328 - accuracy: 0.9739 - val_loss: 0.3481 - val_accuracy: 0.9652\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 235s 1s/step - loss: 0.3289 - accuracy: 0.9732 - val_loss: 0.3441 - val_accuracy: 0.9676\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 238s 1s/step - loss: 0.3296 - accuracy: 0.9731 - val_loss: 0.3394 - val_accuracy: 0.9680\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 238s 1s/step - loss: 0.3285 - accuracy: 0.9735 - val_loss: 0.3443 - val_accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 238s 1s/step - loss: 0.3258 - accuracy: 0.9750 - val_loss: 0.3415 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS), \n",
    "            validation_data=(testX, testY), \n",
    "            #steps_per_epoch=len(trainX),\n",
    "            epochs=EPOCHS,\n",
    "            class_weight=classWeight,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.99      0.99       191\n",
      "           B       0.94      0.97      0.96       188\n",
      "           C       0.99      0.92      0.96       226\n",
      "           D       0.99      0.97      0.98       225\n",
      "           E       0.94      0.97      0.96       194\n",
      "           F       0.95      0.97      0.96       203\n",
      "           G       0.95      0.95      0.95       216\n",
      "           H       0.98      0.98      0.98       193\n",
      "           I       0.95      0.94      0.94       186\n",
      "           J       0.96      0.96      0.96       219\n",
      "           K       0.98      0.98      0.98       212\n",
      "           L       0.99      0.97      0.98       194\n",
      "           M       0.97      0.99      0.98       210\n",
      "           N       0.99      0.95      0.97       188\n",
      "           O       0.99      0.99      0.99       213\n",
      "           P       0.96      0.97      0.97       210\n",
      "           Q       0.96      0.97      0.97       191\n",
      "           R       1.00      0.98      0.99       211\n",
      "           S       0.91      0.96      0.93       211\n",
      "           T       0.98      0.96      0.97       190\n",
      "           U       0.96      0.97      0.97       199\n",
      "           V       1.00      0.98      0.99       223\n",
      "           W       1.00      0.98      0.99       193\n",
      "           X       0.97      0.98      0.97       203\n",
      "           Y       0.96      0.97      0.97       202\n",
      "           Z       0.95      0.96      0.95       193\n",
      "\n",
      "    accuracy                           0.97      5284\n",
      "   macro avg       0.97      0.97      0.97      5284\n",
      "weighted avg       0.97      0.97      0.97      5284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_only_capital.model\"\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_only_capital.model\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "images = [] \n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "\n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
    "\n",
    "cv2.imshow(\"OCR Results\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading OCR model...\n",
      "C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_only_capital.model\n",
      "[INFO] A - 99.57%\n",
      "[INFO] F - 99.22%\n",
      "[INFO] A - 99.71%\n",
      "[INFO] S - 99.13%\n",
      "[INFO] T - 91.55%\n",
      "[INFO] E - 99.81%\n",
      "[INFO] S - 98.98%\n",
      "[INFO] E - 99.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "model_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\model\\trained_ocr_only_capital.model\"\n",
    "\n",
    "print(\"[INFO] loading OCR model...\")\n",
    "model = load_model(model_path)\n",
    "print(model_path)\n",
    "\n",
    "image_path = r\"C:\\Projetos\\Mestrado\\Project II\\SourceCode\\TextIdentificationService\\images\\placa-perigo.png\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "\n",
    "chars = []\n",
    "\n",
    "for c in cnts:\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\tif (w >= 20 and w <= 150) and (h >= 15 and h <= 120):\n",
    "\t\troi = gray[y:y + h, x:x + w]\n",
    "\t\tthresh = cv2.threshold(roi, 0, 255,\n",
    "\t\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\t\t(tH, tW) = thresh.shape\n",
    "\n",
    "\t\tif tW > tH:\n",
    "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
    "\t\telse:\n",
    "\t\t\tthresh = imutils.resize(thresh, height=32)\n",
    "\n",
    "\t\t(tH, tW) = thresh.shape\n",
    "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
    "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
    "\n",
    "\t\tpadded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
    "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "\t\t\tvalue=(255, 255, 255))\n",
    "\t\t\n",
    "\t\tpadded = cv2.resize(padded, (32, 32))\n",
    "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
    "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "\t\tchars.append((padded, (x, y, w, h)))\n",
    "\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "\n",
    "preds = model.predict(chars)\n",
    "\n",
    "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "\ti = np.argmax(pred)\n",
    "\tprob = pred[i]\n",
    "\tif prob > 0.8:\n",
    "\t\tlabel = labelNames[i]\n",
    "\n",
    "\t\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\tcv2.putText(image, label, (x - 10, y - 10),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c24eadc24cde19d3a8e63a432684b30729b59b97047879d8d8cf2273aafd7845"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
